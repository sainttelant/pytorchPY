{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XUEWEI\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch[001/001] Iteration[010/500] Loss: 1.1653 Acc:56.88%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[020/500] Loss: 1.3130 Acc:54.06%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[030/500] Loss: 1.2702 Acc:54.17%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[040/500] Loss: 1.1492 Acc:54.69%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[050/500] Loss: 1.2808 Acc:54.12%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[060/500] Loss: 1.3486 Acc:53.96%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[070/500] Loss: 1.3335 Acc:53.66%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[080/500] Loss: 1.4088 Acc:52.66%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[090/500] Loss: 1.2284 Acc:53.54%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[100/500] Loss: 1.4126 Acc:53.44%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[110/500] Loss: 1.2233 Acc:53.64%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[120/500] Loss: 1.1507 Acc:54.27%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[130/500] Loss: 1.2084 Acc:54.42%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[140/500] Loss: 1.2535 Acc:54.24%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[150/500] Loss: 1.1887 Acc:54.46%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[160/500] Loss: 1.1039 Acc:54.61%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[170/500] Loss: 1.5766 Acc:54.15%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[180/500] Loss: 1.2714 Acc:54.31%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[190/500] Loss: 1.2095 Acc:54.47%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[200/500] Loss: 1.2184 Acc:54.62%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[210/500] Loss: 1.2677 Acc:54.49%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[220/500] Loss: 1.1611 Acc:54.69%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[230/500] Loss: 1.3907 Acc:54.37%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[240/500] Loss: 1.2757 Acc:54.19%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[250/500] Loss: 1.3792 Acc:54.10%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[260/500] Loss: 1.2781 Acc:54.13%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[270/500] Loss: 1.3728 Acc:53.94%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[280/500] Loss: 1.2939 Acc:53.91%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[290/500] Loss: 1.2969 Acc:53.90%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[300/500] Loss: 1.3409 Acc:53.71%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[310/500] Loss: 1.2540 Acc:53.71%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[320/500] Loss: 1.2777 Acc:53.77%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[330/500] Loss: 1.2045 Acc:54.00%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[340/500] Loss: 1.2685 Acc:53.95%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[350/500] Loss: 1.3585 Acc:53.73%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[360/500] Loss: 1.3621 Acc:53.75%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[370/500] Loss: 1.2632 Acc:54.00%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[380/500] Loss: 1.2357 Acc:54.10%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[390/500] Loss: 1.2896 Acc:54.09%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[400/500] Loss: 1.1811 Acc:54.19%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[410/500] Loss: 1.1641 Acc:54.30%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[420/500] Loss: 1.2451 Acc:54.40%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[430/500] Loss: 1.2861 Acc:54.39%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[440/500] Loss: 1.2925 Acc:54.26%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[450/500] Loss: 1.2658 Acc:54.26%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[460/500] Loss: 1.3884 Acc:54.21%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[470/500] Loss: 1.3076 Acc:54.14%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[480/500] Loss: 1.1680 Acc:54.17%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[490/500] Loss: 1.1000 Acc:54.26%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Training: Epoch[001/001] Iteration[500/500] Loss: 1.2832 Acc:54.26%\n",
      "参数组1的学习率:0.001, 参数组2的学习率:0.01\n",
      "Valid set Accuracy:56.40%\n",
      "Finished Training\n",
      "class:plane     , total num:800.0 , correct num:572.0  Recall: 71.41% Precision: 54.74%\n",
      "class:car       , total num:800.0 , correct num:548.0  Recall: 68.41% Precision: 68.24%\n",
      "class:bird      , total num:800.0 , correct num:333.0  Recall: 41.57% Precision: 46.97%\n",
      "class:cat       , total num:800.0 , correct num:370.0  Recall: 46.19% Precision: 38.54%\n",
      "class:deer      , total num:800.0 , correct num:341.0  Recall: 42.57% Precision: 42.36%\n",
      "class:dog       , total num:800.0 , correct num:268.0  Recall: 33.46% Precision: 55.49%\n",
      "class:frog      , total num:800.0 , correct num:648.0  Recall: 80.90% Precision: 54.09%\n",
      "class:horse     , total num:800.0 , correct num:297.0  Recall: 37.08% Precision: 80.27%\n",
      "class:ship      , total num:800.0 , correct num:582.0  Recall: 72.66% Precision: 53.35%\n",
      "class:truck     , total num:800.0 , correct num:398.0  Recall: 49.69% Precision: 72.89%\n",
      "train set Accuracy:54.46%\n",
      "class:plane     , total num:100.0 , correct num:73.0   Recall: 72.28% Precision: 50.69%\n",
      "class:car       , total num:100.0 , correct num:80.0   Recall: 79.21% Precision: 62.99%\n",
      "class:bird      , total num:100.0 , correct num:50.0   Recall: 49.50% Precision: 56.18%\n",
      "class:cat       , total num:100.0 , correct num:43.0   Recall: 42.57% Precision: 40.19%\n",
      "class:deer      , total num:100.0 , correct num:40.0   Recall: 39.60% Precision: 43.01%\n",
      "class:dog       , total num:100.0 , correct num:38.0   Recall: 37.62% Precision: 51.35%\n",
      "class:frog      , total num:100.0 , correct num:90.0   Recall: 89.11% Precision: 53.57%\n",
      "class:horse     , total num:100.0 , correct num:44.0   Recall: 43.56% Precision: 83.02%\n",
      "class:ship      , total num:100.0 , correct num:57.0   Recall: 56.44% Precision: 61.96%\n",
      "class:truck     , total num:100.0 , correct num:49.0   Recall: 48.51% Precision: 77.78%\n",
      "valid set Accuracy:56.40%\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.utils import MyDataset, validate, show_confMat\n",
    "from datetime import datetime\n",
    "\n",
    "train_txt_path = 'Data/train.txt'\n",
    "valid_txt_path = 'Data/valid.txt'\n",
    "\n",
    "classes_name = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_bs = 16\n",
    "valid_bs = 16\n",
    "lr_init = 0.001\n",
    "max_epoch = 1\n",
    "\n",
    "# log\n",
    "result_dir = '../../Result/'\n",
    "\n",
    "now_time = datetime.now()\n",
    "time_str = datetime.strftime(now_time, '%m-%d_%H-%M-%S')\n",
    "\n",
    "log_dir = os.path.join(result_dir, time_str)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# -------------------------------------------- step 1/5 : 加载数据 -------------------------------------------\n",
    "\n",
    "# 数据预处理设置\n",
    "normMean = [0.4948052, 0.48568845, 0.44682974]\n",
    "normStd = [0.24580306, 0.24236229, 0.2603115]\n",
    "normTransform = transforms.Normalize(normMean, normStd)\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "validTransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "# 构建MyDataset实例\n",
    "train_data = MyDataset(txt_path=train_txt_path, transform=trainTransform)\n",
    "valid_data = MyDataset(txt_path=valid_txt_path, transform=validTransform)\n",
    "\n",
    "# 构建DataLoder\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=train_bs, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=valid_bs)\n",
    "\n",
    "# ------------------------------------ step 2/5 : 定义网络 ------------------------------------\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # 定义权值初始化\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "net = Net()     # 创建一个网络\n",
    "\n",
    "# ================================ #\n",
    "#        finetune 权值初始化\n",
    "# ================================ #\n",
    "\n",
    "# load params\n",
    "pretrained_dict = torch.load('net_params.pkl')\n",
    "\n",
    "# 获取当前网络的dict\n",
    "net_state_dict = net.state_dict()\n",
    "\n",
    "# 剔除不匹配的权值参数\n",
    "pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "\n",
    "# 更新新模型参数字典\n",
    "net_state_dict.update(pretrained_dict_1)\n",
    "\n",
    "# 将包含预训练模型参数的字典\"放\"到新模型中\n",
    "net.load_state_dict(net_state_dict)\n",
    "\n",
    "# ------------------------------------ step 3/5 : 定义损失函数和优化器 ------------------------------------\n",
    "# ================================= #\n",
    "#         按需设置学习率\n",
    "# ================================= #\n",
    "\n",
    "# 将fc3层的参数从原始网络参数中剔除\n",
    "ignored_params = list(map(id, net.fc3.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params, net.parameters())\n",
    "\n",
    "# 为fc3层设置需要的学习率\n",
    "optimizer = optim.SGD([\n",
    "    {'params': base_params},\n",
    "    {'params': net.fc3.parameters(), 'lr': lr_init*10}],  lr_init, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()                                                   # 选择损失函数\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)     # 设置学习率下降策略\n",
    "\n",
    "# ------------------------------------ step 4/5 : 训练 --------------------------------------------------\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    loss_sigma = 0.0    # 记录一个epoch的loss之和\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    scheduler.step()  # 更新学习率\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # 获取图片和标签\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # forward, backward, update weights\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计预测信息\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).squeeze().sum().numpy()\n",
    "        loss_sigma += loss.item()\n",
    "\n",
    "        # 每10个iteration 打印一次训练信息，loss为10个iteration的平均\n",
    "        if i % 10 == 9:\n",
    "            loss_avg = loss_sigma / 10\n",
    "            loss_sigma = 0.0\n",
    "            print(\"Training: Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "                epoch + 1, max_epoch, i + 1, len(train_loader), loss_avg, correct / total))\n",
    "            print('参数组1的学习率:{}, 参数组2的学习率:{}'.format(scheduler.get_lr()[0], scheduler.get_lr()[1]))\n",
    "    # ------------------------------------ 观察模型在验证集上的表现 ------------------------------------\n",
    "    loss_sigma = 0.0\n",
    "    cls_num = len(classes_name)\n",
    "    conf_mat = np.zeros([cls_num, cls_num])  # 混淆矩阵\n",
    "    net.eval()\n",
    "    for i, data in enumerate(valid_loader):\n",
    "\n",
    "        # 获取图片和标签\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "\n",
    "        # forward\n",
    "        outputs = net(images)\n",
    "        outputs.detach_()\n",
    "\n",
    "        # 计算loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_sigma += loss.item()\n",
    "\n",
    "        # 统计\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # labels = labels.data    # Variable --> tensor\n",
    "\n",
    "        # 统计混淆矩阵\n",
    "        for j in range(len(labels)):\n",
    "            cate_i = labels[j].numpy()\n",
    "            pre_i = predicted[j].numpy()\n",
    "            conf_mat[cate_i, pre_i] += 1.0\n",
    "\n",
    "    print('{} set Accuracy:{:.2%}'.format('Valid', conf_mat.trace() / conf_mat.sum()))\n",
    "print('Finished Training')\n",
    "\n",
    "# ------------------------------------ step5: 绘制混淆矩阵图 ------------------------------------\n",
    "\n",
    "conf_mat_train, train_acc = validate(net, train_loader, 'train', classes_name)\n",
    "conf_mat_valid, valid_acc = validate(net, valid_loader, 'valid', classes_name)\n",
    "\n",
    "show_confMat(conf_mat_train, classes_name, 'train', log_dir)\n",
    "show_confMat(conf_mat_valid, classes_name, 'valid', log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
