{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XUEWEI\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch[001/001] Iteration[010/500] Loss: 2.3027 Acc:5.62%\n",
      "Training: Epoch[001/001] Iteration[020/500] Loss: 2.3026 Acc:7.50%\n",
      "Training: Epoch[001/001] Iteration[030/500] Loss: 2.3027 Acc:7.50%\n",
      "Training: Epoch[001/001] Iteration[040/500] Loss: 2.3022 Acc:9.84%\n",
      "Training: Epoch[001/001] Iteration[050/500] Loss: 2.3030 Acc:10.00%\n",
      "Training: Epoch[001/001] Iteration[060/500] Loss: 2.3026 Acc:10.10%\n",
      "Training: Epoch[001/001] Iteration[070/500] Loss: 2.3031 Acc:9.82%\n",
      "Training: Epoch[001/001] Iteration[080/500] Loss: 2.3024 Acc:9.77%\n",
      "Training: Epoch[001/001] Iteration[090/500] Loss: 2.3022 Acc:9.58%\n",
      "Training: Epoch[001/001] Iteration[100/500] Loss: 2.3028 Acc:9.81%\n",
      "Training: Epoch[001/001] Iteration[110/500] Loss: 2.3027 Acc:9.60%\n",
      "Training: Epoch[001/001] Iteration[120/500] Loss: 2.3039 Acc:9.53%\n",
      "Training: Epoch[001/001] Iteration[130/500] Loss: 2.3023 Acc:9.33%\n",
      "Training: Epoch[001/001] Iteration[140/500] Loss: 2.3030 Acc:9.29%\n",
      "Training: Epoch[001/001] Iteration[150/500] Loss: 2.3031 Acc:9.12%\n",
      "Training: Epoch[001/001] Iteration[160/500] Loss: 2.3027 Acc:9.18%\n",
      "Training: Epoch[001/001] Iteration[170/500] Loss: 2.3034 Acc:9.12%\n",
      "Training: Epoch[001/001] Iteration[180/500] Loss: 2.3028 Acc:8.89%\n",
      "Training: Epoch[001/001] Iteration[190/500] Loss: 2.3029 Acc:8.72%\n",
      "Training: Epoch[001/001] Iteration[200/500] Loss: 2.3027 Acc:8.84%\n",
      "Training: Epoch[001/001] Iteration[210/500] Loss: 2.3030 Acc:8.72%\n",
      "Training: Epoch[001/001] Iteration[220/500] Loss: 2.3025 Acc:8.75%\n",
      "Training: Epoch[001/001] Iteration[230/500] Loss: 2.3023 Acc:9.05%\n",
      "Training: Epoch[001/001] Iteration[240/500] Loss: 2.3034 Acc:9.01%\n",
      "Training: Epoch[001/001] Iteration[250/500] Loss: 2.3032 Acc:8.90%\n",
      "Training: Epoch[001/001] Iteration[260/500] Loss: 2.3021 Acc:8.89%\n",
      "Training: Epoch[001/001] Iteration[270/500] Loss: 2.3032 Acc:8.77%\n",
      "Training: Epoch[001/001] Iteration[280/500] Loss: 2.3024 Acc:8.93%\n",
      "Training: Epoch[001/001] Iteration[290/500] Loss: 2.3024 Acc:9.05%\n",
      "Training: Epoch[001/001] Iteration[300/500] Loss: 2.3031 Acc:9.04%\n",
      "Training: Epoch[001/001] Iteration[310/500] Loss: 2.3030 Acc:8.97%\n",
      "Training: Epoch[001/001] Iteration[320/500] Loss: 2.3028 Acc:9.08%\n",
      "Training: Epoch[001/001] Iteration[330/500] Loss: 2.3015 Acc:9.32%\n",
      "Training: Epoch[001/001] Iteration[340/500] Loss: 2.3041 Acc:9.25%\n",
      "Training: Epoch[001/001] Iteration[350/500] Loss: 2.3031 Acc:9.20%\n",
      "Training: Epoch[001/001] Iteration[360/500] Loss: 2.3027 Acc:9.24%\n",
      "Training: Epoch[001/001] Iteration[370/500] Loss: 2.3026 Acc:9.17%\n",
      "Training: Epoch[001/001] Iteration[380/500] Loss: 2.3029 Acc:9.16%\n",
      "Training: Epoch[001/001] Iteration[390/500] Loss: 2.3027 Acc:9.18%\n",
      "Training: Epoch[001/001] Iteration[400/500] Loss: 2.3025 Acc:9.19%\n",
      "Training: Epoch[001/001] Iteration[410/500] Loss: 2.3037 Acc:9.19%\n",
      "Training: Epoch[001/001] Iteration[420/500] Loss: 2.3038 Acc:9.12%\n",
      "Training: Epoch[001/001] Iteration[430/500] Loss: 2.3029 Acc:9.16%\n",
      "Training: Epoch[001/001] Iteration[440/500] Loss: 2.3031 Acc:9.12%\n",
      "Training: Epoch[001/001] Iteration[450/500] Loss: 2.3035 Acc:9.08%\n",
      "Training: Epoch[001/001] Iteration[460/500] Loss: 2.3028 Acc:9.06%\n",
      "Training: Epoch[001/001] Iteration[470/500] Loss: 2.3027 Acc:9.04%\n",
      "Training: Epoch[001/001] Iteration[480/500] Loss: 2.3026 Acc:9.08%\n",
      "Training: Epoch[001/001] Iteration[490/500] Loss: 2.3028 Acc:9.09%\n",
      "Training: Epoch[001/001] Iteration[500/500] Loss: 2.3029 Acc:9.10%\n",
      "Valid set Accuracy:10.00%\n",
      "Finished Training\n",
      "class:plane     , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:car       , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:bird      , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:cat       , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:deer      , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:dog       , total num:800.0 , correct num:800.0  Recall: 99.88% Precision: 10.00%\n",
      "class:frog      , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:horse     , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:ship      , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:truck     , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "train set Accuracy:10.00%\n",
      "class:plane     , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:car       , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:bird      , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:cat       , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:deer      , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:dog       , total num:100.0 , correct num:100.0  Recall: 99.01% Precision: 9.99%\n",
      "class:frog      , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:horse     , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:ship      , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:truck     , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "valid set Accuracy:10.00%\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.utils import MyDataset, validate, show_confMat\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "train_txt_path = 'Data/train.txt'\n",
    "valid_txt_path = 'Data/valid.txt'\n",
    "\n",
    "classes_name = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_bs = 16\n",
    "valid_bs = 16\n",
    "lr_init = 0.001\n",
    "max_epoch = 1\n",
    "\n",
    "# log\n",
    "result_dir = '../../Result/'\n",
    "\n",
    "now_time = datetime.now()\n",
    "time_str = datetime.strftime(now_time, '%m-%d_%H-%M-%S')\n",
    "\n",
    "log_dir = os.path.join(result_dir, time_str)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# ------------------------------------ step 1/5 : 加载数据------------------------------------\n",
    "\n",
    "# 数据预处理设置\n",
    "normMean = [0.49149027, 0.48492792, 0.45154625]\n",
    "normStd = [0.24520883, 0.24136706, 0.2609891]\n",
    "normTransform = transforms.Normalize(normMean, normStd)\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "validTransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "# 构建MyDataset实例\n",
    "train_data = MyDataset(txt_path=train_txt_path, transform=trainTransform)\n",
    "valid_data = MyDataset(txt_path=valid_txt_path, transform=validTransform)\n",
    "\n",
    "# 构建DataLoder\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=train_bs, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=valid_bs)\n",
    "\n",
    "# ------------------------------------ step 2/5 : 定义网络------------------------------------\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # 定义权值初始化\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "net = Net()     # 创建一个网络\n",
    "net.initialize_weights()    # 初始化权值\n",
    "\n",
    "# ------------------------------------ step 3/5 : 定义损失函数和优化器 ------------------------------------\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()                                                   # 选择损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr_init, momentum=0.9, dampening=0.1)    # 选择优化器\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)     # 设置学习率下降策略\n",
    "\n",
    "# ------------------------------------ step 4/5 : 训练 --------------------------------------------------\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    loss_sigma = 0.0    # 记录一个epoch的loss之和\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    scheduler.step()  # 更新学习率\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # if i == 30 : break\n",
    "        # 获取图片和标签\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # forward, backward, update weights\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计预测信息\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).squeeze().sum().numpy()\n",
    "        loss_sigma += loss.item()\n",
    "\n",
    "        # 每10个iteration 打印一次训练信息，loss为10个iteration的平均\n",
    "        if i % 10 == 9:\n",
    "            loss_avg = loss_sigma / 10\n",
    "            loss_sigma = 0.0\n",
    "            print(\"Training: Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "                epoch + 1, max_epoch, i + 1, len(train_loader), loss_avg, correct / total))\n",
    "\n",
    "            # 记录训练loss\n",
    "            writer.add_scalars('Loss_group', {'train_loss': loss_avg}, epoch)\n",
    "            # 记录learning rate\n",
    "            writer.add_scalar('learning rate', scheduler.get_lr()[0], epoch)\n",
    "            # 记录Accuracy\n",
    "            writer.add_scalars('Accuracy_group', {'train_acc': correct / total}, epoch)\n",
    "\n",
    "    # 每个epoch，记录梯度，权值\n",
    "    for name, layer in net.named_parameters():\n",
    "        writer.add_histogram(name + '_grad', layer.grad.cpu().data.numpy(), epoch)\n",
    "        writer.add_histogram(name + '_data', layer.cpu().data.numpy(), epoch)\n",
    "\n",
    "    # ------------------------------------ 观察模型在验证集上的表现 ------------------------------------\n",
    "    if epoch % 2 == 0:\n",
    "        loss_sigma = 0.0\n",
    "        cls_num = len(classes_name)\n",
    "        conf_mat = np.zeros([cls_num, cls_num])  # 混淆矩阵\n",
    "        net.eval()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "\n",
    "            # 获取图片和标签\n",
    "            images, labels = data\n",
    "            images, labels = Variable(images), Variable(labels)\n",
    "\n",
    "            # forward\n",
    "            outputs = net(images)\n",
    "            outputs.detach_()\n",
    "\n",
    "            # 计算loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sigma += loss.item()\n",
    "\n",
    "            # 统计\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # labels = labels.data    # Variable --> tensor\n",
    "\n",
    "            # 统计混淆矩阵\n",
    "            for j in range(len(labels)):\n",
    "                cate_i = labels[j].numpy()\n",
    "                pre_i = predicted[j].numpy()\n",
    "                conf_mat[cate_i, pre_i] += 1.0\n",
    "\n",
    "        print('{} set Accuracy:{:.2%}'.format('Valid', conf_mat.trace() / conf_mat.sum()))\n",
    "        # 记录Loss, accuracy\n",
    "        writer.add_scalars('Loss_group', {'valid_loss': loss_sigma / len(valid_loader)}, epoch)\n",
    "        writer.add_scalars('Accuracy_group', {'valid_acc': conf_mat.trace() / conf_mat.sum()}, epoch)\n",
    "print('Finished Training')\n",
    "\n",
    "# ------------------------------------ step5: 保存模型 并且绘制混淆矩阵图 ------------------------------------\n",
    "net_save_path = os.path.join(log_dir, 'net_params.pkl')\n",
    "torch.save(net.state_dict(), net_save_path)\n",
    "\n",
    "conf_mat_train, train_acc = validate(net, train_loader, 'train', classes_name)\n",
    "conf_mat_valid, valid_acc = validate(net, valid_loader, 'valid', classes_name)\n",
    "\n",
    "show_confMat(conf_mat_train, classes_name, 'train', log_dir)\n",
    "show_confMat(conf_mat_valid, classes_name, 'valid', log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
